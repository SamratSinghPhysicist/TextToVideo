"""
Final Video Generator with Karaoke Subtitles (Word‑Level Highlighting)
-----------------------------------------------------------------------
This script builds a vertical video (1080×1920) for YouTube Shorts using:
 • A continuous voiceover (one audio file for the complete video)
 • A script divided into scenes (each separated by two newlines)
 • An images mapping (one image per scene)
 • For each scene:
     - An image clip with a Ken Burns–style zoom effect
     - A karaoke subtitle clip that highlights each word as it is “spoken”
       (word timings are generated by equally splitting the scene duration)
     
NOTE:
– This example uses a naive equal‑split method for word timings.
– For improved accuracy, consider using a free forced‑alignment tool (e.g., Aeneas).
– All tools used here are free.
"""

import os
from moviepy.editor import (ImageClip, TextClip, CompositeVideoClip,
                            concatenate_videoclips, AudioFileClip, ColorClip)
from moviepy.config import change_settings

# Set the ImageMagick binary path (update as needed)
change_settings({"IMAGEMAGICK_BINARY": r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\magick.exe"})

# Global final resolution for YouTube Shorts (vertical video)
FINAL_SIZE = (1080, 1920)

def create_image_scene_clip(image_path, duration, transition_duration=1):
    """
    Create an image clip with a Ken Burns–style zoom effect,
    scaled to the vertical FINAL_SIZE.
    """
    # Load image clip and set duration
    image = ImageClip(image_path).set_duration(duration)
    
    # Scale image to fit FINAL_SIZE while preserving aspect ratio
    original_size = image.size  # (width, height)
    target_width, target_height = FINAL_SIZE
    scale_factor = min(target_width / original_size[0], target_height / original_size[1])
    image = image.resize(scale_factor)
    
    # Apply a subtle Ken Burns zoom effect (5% zoom over duration)
    image = image.resize(lambda t: 1 + 0.05 * (t / duration))
    
    # Create a black background clip of FINAL_SIZE
    background = ColorClip(FINAL_SIZE, color=(0, 0, 0), duration=duration)
    
    # Composite the image over the background (centered)
    composite_clip = CompositeVideoClip([background, image.set_position("center")], size=FINAL_SIZE)
    
    # Add fade in/out transitions for smoothness
    composite_clip = composite_clip.fadein(transition_duration).fadeout(transition_duration)
    
    return composite_clip

def create_karaoke_subtitle(scene_text, duration, gap=20, fontsize=40):
    """
    Create a karaoke-style subtitle clip with word‑by‑word highlighting.
    
    This function splits the scene_text into words and assigns each word
    an equal time interval within the scene duration. Each word is rendered
    twice:
      • A base clip (white text) always visible.
      • A highlight clip (yellow text) that appears only during that word's time.
      
    The word clips are positioned side‑by‑side and centered horizontally.
    
    Parameters:
      scene_text : Full text for the scene.
      duration   : Duration (seconds) of the scene.
      gap        : Horizontal gap (pixels) between words.
      fontsize   : Font size for the subtitle.
      
    Returns:
      A CompositeVideoClip of the karaoke subtitle.
    """
    words = scene_text.split()
    n = len(words)
    if n == 0:
        return None  # No subtitle if no words
    
    # Generate word timings by equally dividing the duration
    word_timings = []
    for i, word in enumerate(words):
        start = (i / n) * duration
        end = ((i + 1) / n) * duration
        word_timings.append({'word': word, 'start': start, 'end': end})
    
    # Measure each word’s width (using a temporary TextClip)
    widths = []
    for word in words:
        temp_clip = TextClip(word, fontsize=fontsize, color='white', font='Arial-Bold', method='caption')
        widths.append(temp_clip.w)
    total_width = sum(widths) + gap * (n - 1)
    
    # Calculate the starting x-coordinate to center the entire line horizontally
    start_x = (FINAL_SIZE[0] - total_width) / 2
    # Estimate vertical position (centered vertically; adjust as needed)
    y_pos = (FINAL_SIZE[1] - 50) / 2  # assuming roughly 50 pixels height
    
    word_clips = []
    current_x = start_x
    for i, word in enumerate(words):
        # Base clip: always visible white text
        base = TextClip(word, fontsize=fontsize, color='white', font='Arial-Bold', method='caption')
        base = base.set_duration(duration).set_position((current_x, y_pos))
        
        # Highlight clip: yellow text visible only during the word's time interval
        highlight = TextClip(word, fontsize=fontsize, color='yellow', font='Arial-Bold', method='caption')
        highlight = highlight.set_position((current_x, y_pos))
        word_duration = word_timings[i]['end'] - word_timings[i]['start']
        highlight = highlight.set_start(word_timings[i]['start']).set_duration(word_duration)
        
        # Composite the base and highlight clips for the word
        word_composite = CompositeVideoClip([base, highlight], size=FINAL_SIZE).set_duration(duration)
        word_clips.append(word_composite)
        
        current_x += widths[i] + gap
    
    # Composite all word clips into one clip (they are overlaid on the same frame)
    karaoke_clip = CompositeVideoClip(word_clips, size=FINAL_SIZE).set_duration(duration)
    
    return karaoke_clip

def generate_final_video(script, images_mapping, audio_path,
                         output_filename="final_video.mp4", transition_duration=1):
    """
    Generate the final video by combining:
      • An image scene clip (with Ken Burns zoom effect)
      • A karaoke subtitle clip (word-by-word highlighting)
    for each scene, and then concatenating all scenes with a single continuous voiceover.
    
    Parameters:
      script             : Multiline string with scenes separated by double newlines.
      images_mapping     : Dictionary mapping scene keys (e.g., "scene1", "scene2", …)
                           to their corresponding image file paths.
      audio_path         : File path to the continuous voiceover audio.
      output_filename    : Filename for the final output video.
      transition_duration: Duration (seconds) for fade transitions.
    """
    # Split the script into scenes
    scenes = [s.strip() for s in script.split("\n\n") if s.strip()]
    num_scenes = len(scenes)
    if num_scenes == 0:
        print("Error: No scenes found in the script!")
        return
    
    # Load the voiceover audio and get total duration
    voiceover = AudioFileClip(audio_path)
    total_audio_duration = voiceover.duration
    # Divide the total duration equally among scenes
    scene_duration = total_audio_duration / num_scenes
    
    scene_clips = []
    for i, scene_text in enumerate(scenes):
        key = f"scene{i+1}"
        image_path = images_mapping.get(key, os.path.join("video_assets", "placeholder.jpg"))
        
        # Create the image clip (with Ken Burns effect)
        image_clip = create_image_scene_clip(image_path, scene_duration, transition_duration)
        # Create the karaoke subtitle clip for this scene (naively timed)
        karaoke_clip = create_karaoke_subtitle(scene_text, scene_duration)
        # Composite the subtitles on top of the image clip
        if karaoke_clip:
            scene_composite = CompositeVideoClip([image_clip, karaoke_clip], size=FINAL_SIZE).set_duration(scene_duration)
        else:
            scene_composite = image_clip
        
        # For every scene after the first, add a crossfade-in transition
        if i > 0:
            scene_composite = scene_composite.crossfadein(transition_duration)
        
        scene_clips.append(scene_composite)
    
    # Concatenate all scene clips
    final_clip = concatenate_videoclips(scene_clips, method="compose")
    # Set the voiceover as the audio track
    final_clip = final_clip.set_audio(voiceover)
    # Optionally, add an overall fade in/out
    final_clip = final_clip.fadein(transition_duration).fadeout(transition_duration)
    
    # Write the final video to file
    final_clip.write_videofile(output_filename, fps=24, codec="libx264")

if __name__ == "__main__":
    # --------------------------------------------------------------------------
    # Example usage:
    #
    # Replace these example variables with those generated by your own processes
    # (e.g., script_generator, voiceover_generator, image_generator).
    # --------------------------------------------------------------------------
    
    # Example script with three scenes (each separated by two newlines)
    script = (
        "Welcome to our video about unicorn facts.\n\n"
        "Did you know unicorns are a symbol of purity and magic?\n\n"
        "Stay tuned for more amazing unicorn facts!"
    )
    
    # Example images mapping. Keys correspond to scene order.
    images_mapping = {
        "scene1": "video_assets/unicorn_alicorn_purify_heal.jpg",
        "scene2": "video_assets/placeholder.jpg",
        "scene3": "video_assets/Unicorn_Scotland_national_animal.jpg",
    }
    
    # Path to the continuous voiceover audio (e.g., generated via ElevenLabs)
    audio_path = "video_assets/output_speech.mp3"
    
    # Generate and export the final video
    generate_final_video(script, images_mapping, audio_path,
                         output_filename="final_video.mp4", transition_duration=1)
